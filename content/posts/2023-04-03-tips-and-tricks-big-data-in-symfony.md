+++
title = "âœï¸ Astuces pour traiter des gros volumes de donnÃ©es dans Symfony"
date = "2023-04-03"
tags = ["php", "symfony", "database", "doctrine"]
+++

Disclaimer: This post is a copy of my [JoliCode blog post](https://jolicode.com/blog/astuces-pour-traiter-des-gros-volumes-de-donnees-dans-symfony).

Dans la vie d'un dÃ©veloppeur, il arrive forcÃ©ment un moment oÃ¹ l'on doit traiter un volume important de donnÃ©es via une ligne de commande. Et les premiÃ¨res fois, Ã§a fait BOOM ğŸ’¥, on utilise du `memory_limit=-1`, [des optimisations](/blog/redis-et-la-memoire-de-php-sont-dans-un-bateau-il-coule)â€¦ Dans cet article, je dresse une liste des diffÃ©rents points d'attention qui m'ont dÃ©jÃ  Ã©tÃ© utiles, ainsi que des astuces qui peuvent grandement aider Ã  l'utilisation et Ã  la maintenance de votre traitement.
Attention, cette liste n'est pas exhaustive et les diffÃ©rents points peuvent Ãªtre applicables ou non selon votre cas.

## Astuces gÃ©nÃ©riques

En premier, des conseils gÃ©nÃ©riques qui peuvent s'appliquer dans la majoritÃ© des cas :

- **Avoir un repÃ¨re dâ€™avancement.** Cela peut paraÃ®tre trivial, mais avoir une barre dâ€™avancement ou un pourcentage permet de voir rapidement et facilement  la quantitÃ© d'Ã©lÃ©ments Ã  traiter et l'Ã©tat d'avancement. Par exemple, Symfony propose une classe ProgressBar dans son composant Console qui permet de "calculer" le temps de traitement passÃ© ou restant - estimÃ© en fonction de la vitesse Ã  laquelle nos Ã©lÃ©ments ont Ã©tÃ© traitÃ©s jusqu'Ã  prÃ©sent - et la consommation mÃ©moire. Voici un exemple :

```php
ProgressBar::setFormatDefinition('custom', '%current%/%max% [%bar%] %percent:3s%% %elapsed:6s%/%estimated:-6s% %memory:6s% %message%');
$bar = $io->createProgressBar($count);
$bar->setMessage('Starting');
$bar->setFormat('custom');
$bar->start();

foreach ($items as $item) {
	$bar->setMessage(sprintf('Idem ID: %s', $item->getId()));
	$bar->advance();
}

$bar->finish();
```

Utiliser cette technique pose aussi deux soucis. Il faut pouvoir compter les Ã©lÃ©ments en amont, ce qui nâ€™est pas toujours possible. Et il faut faire attention au taux de refresh du repÃ¨re affichÃ© en console pour parfois le rÃ©duire sâ€™il est trop gourmand (il existe [un paramÃ¨tre sur la classe ProgressBar](https://github.com/symfony/symfony/blob/6.3/src/Symfony/Component/Console/Helper/ProgressBar.php#L70) qui permet de gÃ©rer Ã§a).

- **Rendre son traitement tolÃ©rant aux erreurs**, toujours traiter les erreurs via un [channel de log](https://symfony.com/doc/current/logging.html) ou via un rapport. Bien sÃ»r, ce n'est pas une raison pour ignorer ces erreurs, pensez Ã  regarder ce rapport et Ã  agir en consÃ©quence.
- **Ne pas regrouper les traitements**. Une tÃ¢che qui traite beaucoup d'Ã©lÃ©ments va prendre soit du temps, soit de la charge CPU ou elle peut juste planter. Si vous avez plusieurs actions Ã  faire, sÃ©parez les en plusieurs commandes qui pourront Ãªtre lancÃ©es indÃ©pendamment. Jâ€™ai dÃ©jÃ  pu voir une commande qui gÃ©rait des statuts de paiements et qui faisait aussi la dÃ©tection de fraude. Vous pouvez totalement sÃ©parer les deux actions en deux commandes et ainsi rÃ©duire la charge de vos commandes.
- **Rendre votre commande relanÃ§able** sans impact sur son exÃ©cution. En effet, il peut arriver dâ€™avoir de trÃ¨s long processus qui bugguent au milieu, ou mÃªme que la commande soit trop longue pour Ãªtre exÃ©cutÃ©e dâ€™un coup. Il faudra donc pouvoir la lancer plusieurs fois. Pour cela, il existe plusieurs mÃ©thodes. La premiÃ¨re serait dâ€™utiliser un flag quand un Ã©lÃ©ment est dÃ©jÃ  traitÃ©, ce qui permettra de lâ€™exclure au prochain passage. Une seconde mÃ©thode serait dâ€™avoir une borne dans votre commande, par exemple `--continue-after-id` ou encore `--continue-after-date` - ici lâ€™idÃ©e est dâ€™avoir une borne Ã  partir de laquelle on reprend le traitement des Ã©lÃ©ments.
- **Attention Ã  l'utilisation des fonction de manipulation de tableaux**. Par exemple, un `array_merge` au milieu d'une boucle. Il vaut mieux regarder les alternatives pour faire Ã§a en dehors de cette boucle. Vous pouvez aussi prÃ©parer votre donnÃ©e de base pour Ã©viter d'avoir Ã  faire ce genre de manipulation. De faÃ§on plus gÃ©nÃ©rale, il vaut mieux Ã©viter tout ce qui utilise de la mÃ©moire dans une boucle, car plus la boucle est grande, plus lâ€™impact est important pour votre serveur.
- **Un rapport Ã  la fin** vous sera toujours utile. Par exemple, avoir le nombre d'Ã©lÃ©ments traitÃ©s, la durÃ©e de ce traitement, la quantitÃ© de mÃ©moire utilisÃ©e, le nombre de requÃªtes SQL engendrÃ©es etc. Il est Ã©galement intÃ©ressant d'ajouter des indicateurs mÃ©tiers : par exemple si votre commande vÃ©rifie des paiements pour trouver des fraudes potentielles, avoir le nombre de paiements dÃ©tectÃ©s comme "fraude" ou "validÃ©" peut Ãªtre pertinent.
- **ParallÃ©liser sur plusieurs workers** permet aussi de beaucoup accÃ©lÃ©rer le traitement des donnÃ©es. Attention cependant, cela rendra tout de suite votre tÃ¢che beaucoup plus complexe car il va falloir partager votre traitement de base en plusieurs tÃ¢ches en parallÃ¨le de faÃ§on indÃ©pendante.

## Doctrine

Doctrine est souvent utilisÃ© dans les applications Symfony et c'est l'une des sources de donnÃ©es les plus populaires. Je ne pouvais donc pas passer Ã  cÃ´tÃ© d'une section concernant Doctrine ğŸ˜€.

- **Nettoyer lâ€™EntityManager** de Doctrine. De nombreuses requÃªtes vont faire que beaucoup dâ€™objets seront instanciÃ©s et des fuites de mÃ©moire vont apparaÃ®tre Ã  coup sÃ»r. Câ€™est pour cela quâ€™il est recommandÃ© de nettoyer lâ€™EntityManager Ã  chaque tour de boucle ou dÃ¨s que vous le pouvez grÃ¢ce Ã  la mÃ©thode `EntityManager::clear()`.
- **PrÃ©fÃ©rer utiliser `toIterable()`** sur les retours de requÃªtes avec beaucoup de rÃ©sultats. En effet, lorsquâ€™on appelle `getResult()`, Doctrine va prÃ©parer toute la collection d'un coup, et donc potentiellement avec beaucoup d'Ã©lÃ©ments. En utilisant `toIterable()`, on aura les Ã©lÃ©ments hydratÃ©s un par un grÃ¢ce Ã  [un gÃ©nÃ©rateur](https://www.php.net/manual/fr/language.generators.syntax.php).
- **[Borner les requÃªtes](https://stackoverflow.com/questions/8269916/what-is-sliding-window-algorithm-examples#answer-64111403)**. Il peut arriver que nos processus aient des Ã©lÃ©ments traitÃ©s en erreur pour diverses raisons. Câ€™est pour cela quâ€™il est recommandÃ© de borner ses requÃªtes de faÃ§on temporelle (ne rÃ©cupÃ©rer que les Ã©lÃ©ments des 3 derniers jours par exemple). Ainsi, lorsqu'un Ã©lÃ©ment est traitÃ© en erreur, il ne sera automatiquement plus traitÃ© au bout de 3 jours (puisqu'il ne sera plus sÃ©lectionnÃ©). Cela permet de gagner du temps CPU sur vos serveurs une fois la borne dÃ©passÃ©e. Une autre solution est de mettre un compteur de tentatives sur vos Ã©lÃ©ments et dâ€™ignorer les Ã©lÃ©ments Ã  partir dâ€™un certain nombre de tentatives. Et encore une fois, nâ€™oubliez pas de suivre et traiter ces erreurs !
- **RÃ©duire les combinatoires**. GÃ©nÃ©ralement, on prÃ©fÃ¨re tout traiter dans une commande. Par exemple, si on a des paniers clients Ã  supprimer, on fera une commande journaliÃ¨re pour supprimer les paniers expirÃ©s. Mais parfois, il vaut mieux traiter la tÃ¢che en plusieurs parties pour Ã©viter de trop faire dâ€™un coup. Nâ€™hÃ©sitez pas Ã  diviser la tÃ¢che en plusieurs lots pour rÃ©duire leur taille ou leur temps de traitement. Par exemple, une premiÃ¨re commande pour les paniers de la matinÃ©e et une seconde pour les paniers de lâ€™aprÃ¨s-midi.
- **Utiliser des rÃ©fÃ©rences plutÃ´t quâ€™un `find()`**. Quand on doit rÃ©cupÃ©rer une rÃ©fÃ©rence Ã  une entitÃ©,  sans pour autant lui appliquer des traitements directement, il vaut mieux privilÃ©gier lâ€™utilisation de `getReference(Entity::class, $id)`. Cela renverra un proxy de lâ€™objet demandÃ© sans faire de requÃªte vers la base de donnÃ©es, comme le ferait un `find()`. Vous pourrez trouver plus dâ€™informations sur la mÃ©thode `getReference` dans [la documentation Doctrine](https://www.doctrine-project.org/projects/doctrine-orm/en/2.14/reference/advanced-configuration.html#reference-proxies).
- **Bien choisir le mode dâ€™hydratation** lors de lâ€™utilisation de vos requÃªtes SQL. Par dÃ©faut, Doctrine met lâ€™hydratation de vos requÃªtes Ã  `object`. Il va alors transformer le rÃ©sultat de la requÃªte en un objet et garder en mÃ©moire tous les objets ainsi crÃ©Ã©s. Cette hydratation dâ€™objet va forcÃ©ment prendre du temps. Ici, je vous recommande de passer par de lâ€™hydratation `array` voire `scalar` (selon les besoins) pour rÃ©duire au maximum le temps de process de vos donnÃ©es par Doctrine.

```
  object - 113Mib -  575ms
  simple - 106Mib -  457ms
   array - 066Mib -  333ms
  scalar - 066Mib -  291ms
```

- **RÃ©gler le cache Doctrine et sur votre base de donnÃ©es**. Lorsquâ€™on fait de nombreuses fois la mÃªme requÃªte avec possiblement des doublons, il peut Ãªtre trÃ¨s utile de mettre en place du cache cÃ´tÃ© Doctrine. Pour cela il existe trois niveaux de cache dans Doctrine: dâ€™abord le cache sur le mapping entre vos entitÃ©s et les tables en base de donnÃ©es. Puis le Query cache, qui permet de mettre en cache la construction de la requÃªte SQL depuis le <abbr title="Doctrine Query Language">DQL</abbr>. Et le Result cache qui va permettre de conserver les rÃ©sultats de votre requÃªte pour les rÃ©utiliser si la requÃªte venait Ã  Ãªtre exÃ©cutÃ©e une seconde fois. Les caches sur les metadata (donc le mapping) et la query sont activÃ©s par dÃ©faut dans Symfony.
  Aussi, il existe parfois, selon le moteur utilisÃ©, un cache cÃ´tÃ© base de donnÃ©es qui permet de garder les rÃ©sultats des requÃªtes pour ensuite rÃ©pondre plus vite. Pour MySQL il est dÃ©sactivÃ© par dÃ©faut depuis 5.6 et âš ï¸ il a Ã©tÃ© [retirÃ© depuis MySQL 8.0](https://dev.mysql.com/blog-archive/mysql-8-0-retiring-support-for-the-query-cache/).

## Fichier

Il est parfois nÃ©cessaire de traiter de la donnÃ©e provenant dâ€™un fichier, ou bien dâ€™Ã©crire cette donnÃ©e dans un fichier.

- **GÃ©nÃ©rer le contenu du fichier via un fichier temporaire**. Quand on doit crÃ©er de gros fichiers, le fait de les gÃ©nÃ©rer puis de les Ã©crire sur le disque peut utiliser beaucoup de mÃ©moire. Câ€™est pour Ã§a quâ€™il est recommandÃ© de passer par un gÃ©nÃ©rateur et dâ€™Ã©crire dans un fichier temporaire (via l'utilisation de `tmpfile()`) ligne par ligne (au plus petit Ã©lÃ©ment possible) puis dâ€™envoyer le fichier temporaire. Cela Ã©vite dâ€™avoir beaucoup de RAM occupÃ©e par la variable qui va stocker ces donnÃ©es et permet aussi de gÃ©rer plus facilement les soucis de donnÃ©es. Vous pouvez aussi gÃ©nÃ©rer votre propre fichier et utiliser des `file_put_contents()` pour Ã©crire dedans, mais pour ma part, je suis plus habituÃ© Ã  `fwrite` donc la fonction `tmpfile()` est plus adaptÃ©e.
- **GÃ©nÃ©ration de fichiers en asynchrone**. Lorsqu'on gÃ©nÃ¨re des fichiers, la tÃ¢che nous semble toujours rapide au dÃ©but. Puis au fur et Ã  mesure de l'Ã©volution de notre code, le volume de ces fichiers augmente, les rendant de plus en plus lents Ã  gÃ©nÃ©rer. C'est pour cela que je recommande de gÃ©nÃ©rer vos fichiers via un worker asynchrone. De la mÃªme maniÃ¨re, si vous travaillez sur une requÃªte HTTP pour une API, vous pouvez envoyer la gÃ©nÃ©ration du fichier en tÃ¢che de fond. AprÃ¨s, vous pouvez soit mettre en place une interface pour rÃ©cupÃ©rer vos fichiers, soit passer par un envoi de lien dans un email ou autre moyen de notifier la disponibilitÃ© du fichier gÃ©nÃ©rÃ©.

## Monitoring

Et pour finir, on aime traiter de la donnÃ©e, mais il faut aussi la surveiller !

- Lorsque vous faites du traitement de lots de donnÃ©es, pensez Ã  **surveiller les informations systÃ¨me de vos machines** ! RAM, CPU, espace disqueâ€¦ on ne sait jamais ce qui peut poser souci, donc autant avoir un Å“il sur tout ce qui pourrait bloquer ou ralentir votre traitement. On peut imaginer de suivre la RAM utilisÃ©e ou disponible en combinaison dâ€™une barre de progression. Aussi, je ne peux que vous recommander quelques outils comme [Netdata](https://www.netdata.cloud/) ou lâ€™utilisation de sondes de monitoring comme [Datadog](https://www.datadoghq.com/), [Prometheus](https://github.com/prometheus/node_exporter) et bien dâ€™autres.
- Faites attention au **garbage collector de PHP**. En effet, par dÃ©faut, le garbage collector de PHP passera automatiquement quand il dÃ©tecte que 10,000 objets sont instanciÃ©s pour nettoyer tous les objets qui ne sont plus utilisÃ©s. Lorsque vous avez un processus sur beaucoup de donnÃ©es, il peut Ãªtre intÃ©ressant de dÃ©sactiver ce comportement du garbage collector pour le faire vous-mÃªme Ã  la main. Plus dâ€™informations sur [la documentation PHP](https://www.php.net/manual/en/features.gc.collecting-cycles.php).
- Et bien sÃ»r **ajoutez des mÃ©triques mÃ©tiers** ! Par exemple, si l'on doit passer des commandes d'un statut "en attente" Ã  "validÃ©", il peut Ãªtre judicieux de mesurer le nombre de commandes traitÃ©es, le nombre de commandes validÃ©es ou encore le nombre d'erreurs. La moindre information vous aidera Ã  comprendre votre tÃ¢che et suivre le traitement de ces donnÃ©es.

Vous pourrez aussi trouver des astuces pour monitorer votre code PHP simplement dans [un de nos prÃ©cÃ©dents articles de blog](/blog/comment-monitorer-rapidement-du-code-php).

## Pour finir

J'espÃ¨re que ce billet vous aura permis d'apprendre des choses, n'hÃ©sitez pas Ã  y revenir lorsque vous aurez Ã  traiter des gros lots de donnÃ©es. Un peu comme une checklist pour voir ce que nous vous recommandons de faire dans ce cas lÃ . Mais nâ€™oubliez pas quâ€™il existe des outils de profiling qui vous feront remonter les mÃ©triques CPU, RAM, requÃªtes SQLâ€¦ et qui vous permettront dâ€™ajuster vos process avec plus de prÃ©cision ! Je pense faire Ã©voluer cette liste au fur et Ã  mesure et pourquoi pas ajouter vos recommandations si vous en avez. ğŸ˜€